package org.dependencytrack.event.kafka.processor;

import alpine.common.logging.Logger;
import alpine.common.metrics.Metrics;
import alpine.notification.NotificationLevel;
import io.micrometer.core.instrument.Timer;
import org.apache.commons.lang3.exception.ExceptionUtils;
import org.apache.kafka.common.header.Header;
import org.apache.kafka.streams.processor.api.ContextualFixedKeyProcessor;
import org.apache.kafka.streams.processor.api.ContextualProcessor;
import org.apache.kafka.streams.processor.api.FixedKeyRecord;
import org.dependencytrack.event.kafka.KafkaEventHeaders;
import org.dependencytrack.model.AnalyzerIdentity;
import org.dependencytrack.model.Component;
import org.dependencytrack.model.FindingAttribution;
import org.dependencytrack.model.Vulnerability;
import org.dependencytrack.model.VulnerabilityAnalysisLevel;
import org.dependencytrack.notification.NotificationConstants;
import org.dependencytrack.notification.NotificationGroup;
import org.dependencytrack.notification.NotificationScope;
import org.dependencytrack.parser.hyades.ModelConverter;
import org.dependencytrack.persistence.QueryManager;
import org.hyades.proto.vulnanalysis.v1.ScanResult;
import org.hyades.proto.vulnanalysis.v1.ScanStatus;
import org.hyades.proto.vulnanalysis.v1.Scanner;
import org.postgresql.util.PSQLState;

import javax.jdo.JDODataStoreException;
import javax.jdo.PersistenceManager;
import javax.jdo.Query;
import javax.jdo.Transaction;
import java.nio.charset.StandardCharsets;
import java.sql.SQLException;
import java.util.NoSuchElementException;
import java.util.Optional;
import java.util.UUID;

import static org.dependencytrack.util.NotificationUtil.analyzeNotificationCriteria;
import static org.dependencytrack.util.NotificationUtil.dispatchExceptionNotifications;

/**
 * A {@link ContextualProcessor} responsible for processing {@link ScanResult}s.
 * <p>
 * {@link ScanResult}s with status {@link ScanStatus#SCAN_STATUS_COMPLETE} will be forwarded,
 * results of any other status will be dropped after processing.
 */
public class VulnerabilityScanResultProcessor extends ContextualFixedKeyProcessor<UUID, ScanResult, ScanResult> {

    private static final Logger LOGGER = Logger.getLogger(VulnerabilityScanResultProcessor.class);
    private static final Timer TIMER = Timer.builder("vuln_scan_result_processing")
            .description("Time taken to process vulnerability scan results")
            .register(Metrics.getRegistry());

    @Override
    public void process(final FixedKeyRecord<UUID, ScanResult> record) {
        final UUID componentUuid = record.key();
        final ScanResult result = record.value();
        final var scanKeyString = "%s/%s".formatted(result.getKey().getScanToken(), componentUuid);

        if (result.getStatus() == ScanStatus.SCAN_STATUS_COMPLETE) {
            context().forward(record);
            return;
        } else if (result.getStatus() == ScanStatus.SCAN_STATUS_FAILED) {
            final var message = "Scan of component %s with %s failed (scanKey: %s): %s"
                    .formatted(componentUuid, result.getScanner(), scanKeyString, result.getFailureReason());
            dispatchExceptionNotifications(
                    NotificationScope.SYSTEM,
                    NotificationGroup.ANALYZER,
                    NotificationConstants.Title.ANALYZER_ERROR,
                    message,
                    NotificationLevel.ERROR);
            LOGGER.warn(message);
            return;
        } else if (result.getStatus() != ScanStatus.SCAN_STATUS_SUCCESSFUL) {
            LOGGER.warn("Unable to process results with status %s; Dropping record (scanKey: %s)"
                    .formatted(result.getStatus(), scanKeyString));
            return;
        }

        if (result.getVulnerabilitiesCount() == 0) {
            LOGGER.debug("No vulnerabilities identified for component %s by %s (scanKey: %s)"
                    .formatted(componentUuid, result.getScanner(), scanKeyString));
            return;
        }

        final Timer.Sample timerSample = Timer.start();
        try (final var qm = new QueryManager()) {
            final PersistenceManager pm = qm.getPersistenceManager();

            if (!componentExists(pm, componentUuid)) {
                LOGGER.warn("Received result for component %s from %s, but it does not exist (scanKey: %s)"
                        .formatted(componentUuid, result.getScanner(), scanKeyString));
                return;
            }

            for (final org.hyades.proto.vuln.v1.Vulnerability hyadesVuln : result.getVulnerabilitiesList()) {
                final Vulnerability vuln;
                try {
                    vuln = ModelConverter.convert(hyadesVuln);
                } catch (RuntimeException e) {
                    LOGGER.error("""
                            Failed to convert vulnerability %s/%s (reported by %s for component %s) to internal model (scanKey: %s)
                            """.formatted(hyadesVuln.getId(), hyadesVuln.getSource(), result.getScanner(), componentUuid, scanKeyString), e);
                    return;
                }

                try {
                    final Vulnerability persistentVuln = persistVulnerability(pm, vuln);
                    final Component persistentComponent = qm.getObjectByUuid(Component.class, componentUuid);
                    analyzeNotificationCriteria(qm, persistentVuln, persistentComponent, determineAnalysisLevel(record));
                    addVulnerability(qm, persistentComponent, persistentVuln, result.getScanner());
                } catch (RuntimeException e) {
                    // Use a broad catch here, so we can still try to process other
                    // vulnerabilities, even though processing one of them failed.

                    LOGGER.error("""
                            Failed to process vulnerability %s/%s (reported by %s for component %s) (scanKey: %s)
                            """.formatted(vuln.getSource(), vuln.getVulnId(), result.getScanner(), componentUuid, scanKeyString), e);
                }
            }
        } catch (Exception e) {
            LOGGER.error("An unexpected error occurred while processing result from %s for component %s (scanKey: %s)"
                    .formatted(result.getScanner(), componentUuid, scanKeyString), e);
        } finally {
            timerSample.stop(TIMER);
        }
    }

    /**
     * @param pm   The {@link PersistenceManager} to use
     * @param vuln The {@link Vulnerability} to persist
     * @return The persisted {@link Vulnerability}
     * @throws NoSuchElementException When {@code vuln} is from source {@link Vulnerability.Source#INTERNAL}
     *                                but could not be found in the database
     * @throws IllegalStateException  When the vulnerability could not be persisted to the database
     */
    private Vulnerability persistVulnerability(final PersistenceManager pm, final Vulnerability vuln) {
        final int maxRetryAttempts = 3;
        Vulnerability persistentVuln = null;

        // It is possible that the same vulnerability is reported for multiple components in parallel,
        // causing unique constraint violations when attempting to insert into the VULNERABILITY table.
        // In such cases, we can get away with simply retrying to SELECT or INSERT again. We'll attempt
        // up to 3 times before giving up.
        for (int i = 0; i < maxRetryAttempts; i++) {
            final Transaction trx = pm.currentTransaction();
            try {
                trx.begin();

                final Query<Vulnerability> query = pm.newQuery(Vulnerability.class);
                query.setFilter("vulnId == :vulnId && source == :source");
                query.setParameters(vuln.getVulnId(), vuln.getSource());
                persistentVuln = query.executeUnique();
                if (persistentVuln != null) {
                    break;
                }

                // If the vulnerability is internal, it must exist in our database.
                // If it doesn't, then it's either invalid, or the underlying vulnerability record
                // has been removed in the meantime. Do not create a new record in this case.
                if (Vulnerability.Source.INTERNAL.name().equals(vuln.getSource())) {
                    throw new NoSuchElementException("An internal vulnerability with ID %s does not exist".formatted(vuln.getVulnId()));
                }

                persistentVuln = pm.makePersistent(vuln);
                trx.commit();
            } catch (JDODataStoreException e) {
                // TODO: DataNucleus doesn't map constraint violation exceptions very well,
                // so we have to depend on the exception of the underlying JDBC driver to
                // tell us what happened. We currently only handle PostgreSQL, but we'll have
                // to do the same for at least H2 and MSSQL.
                if (ExceptionUtils.getRootCause(e) instanceof final SQLException se
                        && PSQLState.UNIQUE_VIOLATION.getState().equals(se.getSQLState())) {
                    continue; // Retry
                }

                throw e;
            } finally {
                if (trx.isActive()) {
                    trx.rollback();
                }
            }
        }

        return Optional.ofNullable(persistentVuln)
                .orElseThrow(() -> new IllegalStateException(
                        "Failed to persist vulnerability %s after %d attempts".formatted(vuln, maxRetryAttempts)));
    }

    private boolean componentExists(final PersistenceManager pm, final UUID uuid) {
        final Transaction trx = pm.currentTransaction();
        try {
            trx.begin();
            final Query<Component> query = pm.newQuery(Component.class);
            query.setFilter("uuid == :uuid");
            query.setParameters(uuid);
            query.setResult("count(this)");
            return query.executeResultUnique(Long.class) > 0;
        } finally {
            trx.rollback(); // Read-only transaction, no need to commit anything
        }
    }

    private void addVulnerability(final QueryManager qm, final Component component,
                                  final Vulnerability vuln, final Scanner scanner) {
        final PersistenceManager pm = qm.getPersistenceManager();
        final Transaction trx = pm.currentTransaction();
        try {
            trx.begin();
            if (!qm.contains(vuln, component)) {
                component.addVulnerability(vuln);
                pm.makePersistent(new FindingAttribution(component, vuln, getAnalyzerIdentity(scanner), null, null));
                trx.commit();
            }
        } finally {
            if (trx.isActive()) {
                trx.rollback();
            }
        }
    }

    private AnalyzerIdentity getAnalyzerIdentity(final Scanner scanner) {
        return switch (scanner) {
            case SCANNER_INTERNAL -> AnalyzerIdentity.INTERNAL_ANALYZER;
            case SCANNER_OSSINDEX -> AnalyzerIdentity.OSSINDEX_ANALYZER;
            case SCANNER_SNYK -> AnalyzerIdentity.SNYK_ANALYZER;
            default -> AnalyzerIdentity.NONE;
        };
    }

    private VulnerabilityAnalysisLevel determineAnalysisLevel(final FixedKeyRecord<?, ?> record) {
        final Header analysisLevelHeader = record.headers().lastHeader(KafkaEventHeaders.VULN_ANALYSIS_LEVEL);
        if (analysisLevelHeader != null && analysisLevelHeader.value() != null) {
            final var analysisTypeHeaderValue = new String(analysisLevelHeader.value(), StandardCharsets.UTF_8);
            try {
                return VulnerabilityAnalysisLevel.valueOf(analysisTypeHeaderValue);
            } catch (IllegalArgumentException e) {
                LOGGER.warn("The reported analysis type %s is invalid, assuming %s"
                        .formatted(analysisTypeHeaderValue, VulnerabilityAnalysisLevel.PERIODIC_ANALYSIS));
            }
        }

        return VulnerabilityAnalysisLevel.PERIODIC_ANALYSIS;
    }

}
