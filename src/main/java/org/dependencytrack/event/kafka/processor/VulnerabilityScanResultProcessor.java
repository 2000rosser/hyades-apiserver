package org.dependencytrack.event.kafka.processor;

import alpine.Config;
import alpine.common.logging.Logger;
import alpine.common.metrics.Metrics;
import alpine.notification.Notification;
import alpine.notification.NotificationLevel;
import com.google.protobuf.Any;
import com.google.protobuf.Timestamp;
import com.google.protobuf.util.Timestamps;
import io.micrometer.core.instrument.Timer;
import org.apache.kafka.streams.processor.api.ContextualFixedKeyProcessor;
import org.apache.kafka.streams.processor.api.ContextualProcessor;
import org.apache.kafka.streams.processor.api.FixedKeyRecord;
import org.dependencytrack.common.ConfigKey;
import org.dependencytrack.event.kafka.KafkaEventDispatcher;
import org.dependencytrack.event.kafka.KafkaEventHeaders;
import org.dependencytrack.event.kafka.KafkaUtil;
import org.dependencytrack.model.AnalysisJustification;
import org.dependencytrack.model.AnalysisResponse;
import org.dependencytrack.model.AnalysisState;
import org.dependencytrack.model.AnalyzerIdentity;
import org.dependencytrack.model.Vulnerability;
import org.dependencytrack.model.VulnerabilityAlias;
import org.dependencytrack.model.VulnerabilityAnalysisLevel;
import org.dependencytrack.model.mapping.PolicyProtoMapper;
import org.dependencytrack.notification.NotificationConstants;
import org.dependencytrack.notification.NotificationGroup;
import org.dependencytrack.notification.NotificationScope;
import org.dependencytrack.parser.dependencytrack.ModelConverterCdxToVuln;
import org.dependencytrack.persistence.QueryManager;
import org.dependencytrack.persistence.jdbi.NotificationSubjectDao;
import org.dependencytrack.policy.vulnerability.VulnerabilityPolicy;
import org.dependencytrack.policy.vulnerability.VulnerabilityPolicyAnalysis;
import org.dependencytrack.policy.vulnerability.VulnerabilityPolicyEvaluator;
import org.dependencytrack.proto.vulnanalysis.v1.ScanKey;
import org.dependencytrack.proto.vulnanalysis.v1.ScanResult;
import org.dependencytrack.proto.vulnanalysis.v1.ScanStatus;
import org.dependencytrack.proto.vulnanalysis.v1.Scanner;
import org.dependencytrack.proto.vulnanalysis.v1.ScannerResult;
import org.dependencytrack.util.PersistenceUtil;
import org.dependencytrack.util.PersistenceUtil.Differ;
import org.jdbi.v3.core.mapper.reflect.ColumnName;
import org.jdbi.v3.sqlobject.config.RegisterBeanMapper;
import org.jdbi.v3.sqlobject.config.RegisterConstructorMapper;
import org.jdbi.v3.sqlobject.customizer.BindBean;
import org.jdbi.v3.sqlobject.customizer.BindMethods;
import org.jdbi.v3.sqlobject.statement.GetGeneratedKeys;
import org.jdbi.v3.sqlobject.statement.SqlBatch;
import org.jdbi.v3.sqlobject.statement.SqlQuery;

import javax.jdo.Query;
import javax.ws.rs.core.MultivaluedHashMap;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.NoSuchElementException;
import java.util.Objects;
import java.util.ServiceLoader;
import java.util.Set;
import java.util.UUID;
import java.util.function.Function;
import java.util.stream.Collectors;

import static org.datanucleus.PropertyNames.PROPERTY_PERSISTENCE_BY_REACHABILITY_AT_COMMIT;
import static org.datanucleus.PropertyNames.PROPERTY_RETAIN_VALUES;
import static org.dependencytrack.parser.dependencytrack.ModelConverterCdxToVuln.convert;
import static org.dependencytrack.persistence.jdbi.JdbiFactory.jdbi;
import static org.dependencytrack.proto.notification.v1.Group.GROUP_NEW_VULNERABILITY;
import static org.dependencytrack.proto.notification.v1.Group.GROUP_NEW_VULNERABLE_DEPENDENCY;
import static org.dependencytrack.proto.notification.v1.Level.LEVEL_INFORMATIONAL;
import static org.dependencytrack.proto.notification.v1.Scope.SCOPE_PORTFOLIO;
import static org.dependencytrack.proto.vulnanalysis.v1.ScanStatus.SCAN_STATUS_FAILED;
import static org.dependencytrack.proto.vulnanalysis.v1.Scanner.SCANNER_INTERNAL;
import static org.dependencytrack.util.VulnerabilityUtil.canBeMirrored;
import static org.dependencytrack.util.VulnerabilityUtil.isAuthoritativeSource;
import static org.dependencytrack.util.VulnerabilityUtil.isMirroringEnabled;

/**
 * A {@link ContextualProcessor} responsible for processing {@link ScanResult}s.
 */
public class VulnerabilityScanResultProcessor extends ContextualFixedKeyProcessor<ScanKey, ScanResult, ScanResult> {

    private static final Logger LOGGER = Logger.getLogger(VulnerabilityScanResultProcessor.class);
    private static final Timer TIMER = Timer.builder("vuln_scan_result_processing")
            .description("Time taken to process vulnerability scan results")
            .register(Metrics.getRegistry());

    private final KafkaEventDispatcher eventDispatcher = new KafkaEventDispatcher();
    private final VulnerabilityPolicyEvaluator vulnPolicyEvaluator;

    public VulnerabilityScanResultProcessor() {
        this(Config.getInstance().getPropertyAsBoolean(ConfigKey.VULNERABILITY_POLICY_ENABLED)
                ? ServiceLoader.load(VulnerabilityPolicyEvaluator.class).findFirst().orElseThrow()
                : null);
    }

    VulnerabilityScanResultProcessor(final VulnerabilityPolicyEvaluator vulnPolicyEvaluator) {
        this.vulnPolicyEvaluator = vulnPolicyEvaluator;
    }

    @Override
    public void process(final FixedKeyRecord<ScanKey, ScanResult> record) {
        final ScanKey scanKey = record.key();
        final ScanResult result = record.value();
        final UUID componentUuid = UUID.fromString(scanKey.getComponentUuid());
        final VulnerabilityAnalysisLevel analysisLevel = determineAnalysisLevel(record);
        final boolean isNewComponent = determineIsComponentNew(record);

        final Timer.Sample timerSample = Timer.start();
        try (final var qm = new QueryManager()) {
            // Do not unload fields upon commit (why is this even the default WTF).
            qm.getPersistenceManager().setProperty(PROPERTY_RETAIN_VALUES, "true");
            qm.getPersistenceManager().setProperty(PROPERTY_PERSISTENCE_BY_REACHABILITY_AT_COMMIT, "false");

            final Component component = jdbi(qm).withExtension(Dao.class, dao -> dao.getComponentByUuid(componentUuid));
            if (component == null) {
                LOGGER.warn("Received result for component %s, but it does not exist (scanKey: %s)"
                        .formatted(componentUuid, prettyPrint(scanKey)));
                return;
            }

            for (final ScannerResult scannerResult : result.getScannerResultsList()) {
                processScannerResult(qm, component, scanKey, scannerResult, analysisLevel, isNewComponent);
            }
        } catch (Exception e) {
            LOGGER.error("Failed to process scan result for component %s (scanKey: %s)"
                    .formatted(componentUuid, prettyPrint(scanKey)), e);
        } finally {
            timerSample.stop(TIMER);
            context().forward(record);
        }
    }

    private void processScannerResult(final QueryManager qm, final Component component,
                                      final ScanKey scanKey, final ScannerResult scannerResult,
                                      final VulnerabilityAnalysisLevel analysisLevel,
                                      final boolean isNewComponent) {
        if (scannerResult.getStatus() == SCAN_STATUS_FAILED) {
            final var message = "Scan of component %s with %s failed (scanKey: %s): %s"
                    .formatted(component.uuid(), scannerResult.getScanner(), prettyPrint(scanKey), scannerResult.getFailureReason());
            eventDispatcher.dispatchAsync(component.projectUuid(), new Notification()
                    .scope(NotificationScope.SYSTEM)
                    .group(NotificationGroup.ANALYZER)
                    .level(NotificationLevel.ERROR)
                    .title(NotificationConstants.Title.ANALYZER_ERROR)
                    .content(message));
            LOGGER.warn(message);
            return;
        } else if (scannerResult.getStatus() != ScanStatus.SCAN_STATUS_SUCCESSFUL) {
            LOGGER.warn("Unable to process results from %s with status %s; Dropping record (scanKey: %s)"
                    .formatted(scannerResult.getScanner(), scannerResult.getStatus(), prettyPrint(scanKey)));
            return;
        }

        final Set<Vulnerability> syncedVulns = syncVulnerabilities(qm, scanKey, scannerResult);
        LOGGER.debug("Synchronized %d vulnerabilities reported by %s for %s (scanKey: %s)"
                .formatted(syncedVulns.size(), scannerResult.getScanner(), scanKey.getComponentUuid(), prettyPrint(scanKey)));

        final Map<UUID, VulnerabilityPolicy> matchedPoliciesByVulnUuid = maybeEvaluateVulnPolicies(component, syncedVulns);
        LOGGER.debug("Identified policy matches for %d/%d vulnerabilities (scanKey: %s)"
                .formatted(matchedPoliciesByVulnUuid.size(), syncedVulns.size(), prettyPrint(scanKey)));

        final List<UUID> newVulnUuids = synchronizeFindingsAndAnalyses(qm, component, syncedVulns,
                scannerResult.getScanner(), matchedPoliciesByVulnUuid);
        LOGGER.debug("Identified %d new vulnerabilities for %s with %s (scanKey: %s)"
                .formatted(newVulnUuids.size(), scanKey.getComponentUuid(), scannerResult.getScanner(), prettyPrint(scanKey)));

        maybeSendNotifications(qm, component, isNewComponent, analysisLevel, newVulnUuids);
    }

    /**
     * Synchronize vulnerabilities reported in a given {@link ScannerResult} with the datastore.
     *
     * @param qm            The {@link QueryManager} to use
     * @param scanKey       The {@link ScanKey} associated with the {@link ScannerResult}
     * @param scannerResult The {@link ScannerResult} to synchronize vulnerabilities from
     * @return A {@link Set} of synchronized {@link Vulnerability}s
     */
    private Set<Vulnerability> syncVulnerabilities(final QueryManager qm, final ScanKey scanKey, final ScannerResult scannerResult) {
        final var syncedVulns = new HashSet<Vulnerability>();

        for (final org.cyclonedx.proto.v1_4.Vulnerability reportedVuln : scannerResult.getBom().getVulnerabilitiesList()) {
            final Vulnerability vuln;
            try {
                vuln = ModelConverterCdxToVuln.convert(qm, scannerResult.getBom(), reportedVuln, true);
            } catch (RuntimeException e) {
                LOGGER.error("Failed to convert vulnerability %s/%s (reported by %s for component %s) to internal model (scanKey: %s)"
                        .formatted(reportedVuln.getSource(), reportedVuln.getId(), scannerResult.getScanner(), scanKey.getComponentUuid(), prettyPrint(scanKey)), e);
                continue;
            }

            try {
                syncedVulns.add(syncVulnerability(qm, vuln, scannerResult.getScanner()));
                if (vuln.getAliases() != null && !vuln.getAliases().isEmpty()) {
                    for (VulnerabilityAlias alias : vuln.getAliases()) {
                        qm.synchronizeVulnerabilityAlias(alias);
                    }
                }
            } catch (RuntimeException e) {
                // Use a broad catch here, so we can still try to process other
                // vulnerabilities, even though processing one of them failed.

                LOGGER.warn("Failed to synchronize vulnerability %s/%s (reported by %s for component %s; scanKey: %s)"
                        .formatted(vuln.getSource(), vuln.getVulnId(), scannerResult.getScanner(), scanKey.getComponentUuid(), prettyPrint(scanKey)), e);
            }
        }

        // Detach vulnerabilities from JDO persistence context.
        // We do not want to trigger any DB interactions by accessing their fields.
        qm.getPersistenceManager().makeTransientAll(syncedVulns);

        return syncedVulns;
    }

    /**
     * Synchronize a given {@link Vulnerability} as reported by a given {@link Scanner} with the datastore.
     * <p>
     * This method differs from {@link QueryManager#synchronizeVulnerability(Vulnerability, boolean)} in that it expects
     * an active {@link javax.jdo.Transaction}, and only calls setters of existing vulnerabilities when the respective
     * value actually changed, saving network round-trips.
     *
     * @param qm      The {@link QueryManager} to use
     * @param vuln    The {@link Vulnerability} to synchronize
     * @param scanner The {@link AnalyzerIdentity} that reported the vulnerability
     * @return The synchronized {@link Vulnerability}
     * @throws IllegalStateException  When no {@link javax.jdo.Transaction} is active
     * @throws NoSuchElementException When the reported vulnerability is internal, but does not exist in the datastore
     */
    private Vulnerability syncVulnerability(final QueryManager qm, final Vulnerability vuln, final Scanner scanner) {
        // TODO: Refactor this to use JDBI instead.
        // It is possible that the same vulnerability is reported for multiple components in parallel,
        // causing unique constraint violations when attempting to INSERT into the VULNERABILITY table.
        // In such cases, we can get away with simply retrying to SELECT or INSERT again.
        return qm.runInRetryableTransaction(() -> {
            final Vulnerability existingVuln;
            final Query<Vulnerability> query = qm.getPersistenceManager().newQuery(Vulnerability.class);
            try {
                query.setFilter("vulnId == :vulnId && source == :source");
                query.setParameters(vuln.getVulnId(), vuln.getSource());
                existingVuln = query.executeUnique();
            } finally {
                query.closeAll();
            }

            if (existingVuln == null) {
                if (Vulnerability.Source.INTERNAL.name().equals(vuln.getSource())) {
                    throw new NoSuchElementException("An internal vulnerability with ID %s does not exist".formatted(vuln.getVulnId()));
                }

                return qm.getPersistenceManager().makePersistent(vuln);
            }

            if (canUpdateVulnerability(existingVuln, scanner)) {
                final var differ = new Differ<>(existingVuln, vuln);

                // TODO: Consider using something like javers to get a rich diff of WHAT changed; https://github.com/javers/javers
                differ.applyIfChanged("title", Vulnerability::getTitle, existingVuln::setTitle);
                differ.applyIfChanged("subTitle", Vulnerability::getSubTitle, existingVuln::setSubTitle);
                differ.applyIfChanged("description", Vulnerability::getDescription, existingVuln::setDescription);
                differ.applyIfChanged("detail", Vulnerability::getDetail, existingVuln::setDetail);
                differ.applyIfChanged("recommendation", Vulnerability::getRecommendation, existingVuln::setRecommendation);
                differ.applyIfChanged("references", Vulnerability::getReferences, existingVuln::setReferences);
                differ.applyIfChanged("credits", Vulnerability::getCredits, existingVuln::setCredits);
                differ.applyIfChanged("created", Vulnerability::getCreated, existingVuln::setCreated);
                differ.applyIfChanged("published", Vulnerability::getPublished, existingVuln::setPublished);
                differ.applyIfChanged("updated", Vulnerability::getUpdated, existingVuln::setUpdated);
                differ.applyIfChanged("cwes", Vulnerability::getCwes, existingVuln::setCwes);
                // Calling setSeverity nulls all CVSS and OWASP RR fields. getSeverity calculates the severity on-the-fly,
                // and will return UNASSIGNED even when no severity is set explicitly. Thus, calling setSeverity
                // must happen before CVSS and OWASP RR fields are set, to avoid null-ing them again.
                differ.applyIfChanged("severity", Vulnerability::getSeverity, existingVuln::setSeverity);
                differ.applyIfChanged("cvssV2BaseScore", Vulnerability::getCvssV2BaseScore, existingVuln::setCvssV2BaseScore);
                differ.applyIfChanged("cvssV2ImpactSubScore", Vulnerability::getCvssV2ImpactSubScore, existingVuln::setCvssV2ImpactSubScore);
                differ.applyIfChanged("cvssV2ExploitabilitySubScore", Vulnerability::getCvssV2ExploitabilitySubScore, existingVuln::setCvssV2ExploitabilitySubScore);
                differ.applyIfChanged("cvssV2Vector", Vulnerability::getCvssV2Vector, existingVuln::setCvssV2Vector);
                differ.applyIfChanged("cvssv3BaseScore", Vulnerability::getCvssV3BaseScore, existingVuln::setCvssV3BaseScore);
                differ.applyIfChanged("cvssV3ImpactSubScore", Vulnerability::getCvssV3ImpactSubScore, existingVuln::setCvssV3ImpactSubScore);
                differ.applyIfChanged("cvssV3ExploitabilitySubScore", Vulnerability::getCvssV3ExploitabilitySubScore, existingVuln::setCvssV3ExploitabilitySubScore);
                differ.applyIfChanged("cvssV3Vector", Vulnerability::getCvssV3Vector, existingVuln::setCvssV3Vector);
                differ.applyIfChanged("owaspRRLikelihoodScore", Vulnerability::getOwaspRRLikelihoodScore, existingVuln::setOwaspRRLikelihoodScore);
                differ.applyIfChanged("owaspRRTechnicalImpactScore", Vulnerability::getOwaspRRTechnicalImpactScore, existingVuln::setOwaspRRTechnicalImpactScore);
                differ.applyIfChanged("owaspRRBusinessImpactScore", Vulnerability::getOwaspRRBusinessImpactScore, existingVuln::setOwaspRRBusinessImpactScore);
                differ.applyIfChanged("owaspRRVector", Vulnerability::getOwaspRRVector, existingVuln::setOwaspRRVector);
                // Aliases of existingVuln will always be null, as they'd have to be fetched separately.
                // Synchronization of aliases is performed after synchronizing the vulnerability.
                // updated |= applyIfChanged(existingVuln, vuln, Vulnerability::getAliases, existingVuln::setAliases);

                differ.applyIfChanged("vulnerableVersions", Vulnerability::getVulnerableVersions, existingVuln::setVulnerableVersions);
                differ.applyIfChanged("patchedVersions", Vulnerability::getPatchedVersions, existingVuln::setPatchedVersions);
                // EPSS is an additional enrichment that no scanner currently provides.
                // We don't want EPSS scores of CVEs to be purged just because the CVE information came from e.g. OSS Index.
                differ.applyIfNonNullAndChanged("epssScore", Vulnerability::getEpssScore, existingVuln::setEpssScore);
                differ.applyIfNonNullAndChanged("epssPercentile", Vulnerability::getEpssPercentile, existingVuln::setEpssPercentile);

                if (!differ.getDiffs().isEmpty()) {
                    // TODO: Send a notification?
                    //   (But notifications should only be sent if the transaction was committed)
                    // TODO: Reduce to DEBUG; It's set to INFO for testing
                    LOGGER.info("Vulnerability %s/%s was updated by %s: %s".formatted(vuln.getSource(), vuln.getVulnId(), scanner, differ.getDiffs()));
                }
            }

            return existingVuln;
        }, PersistenceUtil::isUniqueConstraintViolation);
    }

    private Map<UUID, VulnerabilityPolicy> maybeEvaluateVulnPolicies(final Component component, final Collection<Vulnerability> vulns) {
        if (vulnPolicyEvaluator == null) {
            return Collections.emptyMap();
        }

        final var policyProject = org.dependencytrack.proto.policy.v1.Project.newBuilder()
                .setUuid(component.projectUuid().toString())
                .build();
        final var policyComponent = org.dependencytrack.proto.policy.v1.Component.newBuilder()
                .setUuid(component.uuid().toString())
                .build();
        final List<org.dependencytrack.proto.policy.v1.Vulnerability> policyVulns = vulns.stream()
                .map(PolicyProtoMapper::mapToProto)
                .toList();

        return vulnPolicyEvaluator.evaluate(policyVulns, policyComponent, policyProject);
    }

    /**
     * Associate a given {@link Set} of {@link Vulnerability}s with a given {@link Component}.
     * <p>
     * If a {@link Vulnerability} was not previously associated with the {@link Component},
     * a {@link FindingAttribution} will be created for the {@link Scanner}.
     *
     * @param qm        The {@link QueryManager} to use
     * @param component The {@link Component} to associate with
     * @param vulns     The {@link Vulnerability}s to associate with
     * @param scanner   The {@link Scanner} that identified the association
     * @return A {@link Collection} of {@link Vulnerability}s that were not previously associated with the {@link Component}
     */
    private List<UUID> synchronizeFindingsAndAnalyses(final QueryManager qm, final Component component,
                                                      final Collection<Vulnerability> vulns, final Scanner scanner,
                                                      final Map<UUID, VulnerabilityPolicy> policiesByVulnUuid) {
        return jdbi(qm).inTransaction(jdbiHandle -> {
            final var dao = jdbiHandle.attach(Dao.class);

            // Bulk-create new findings and corresponding scanner attributions.
            final List<Long> newFindingVulnIds = dao.createFindings(component, vulns);
            final List<FindingAttribution> findingAttributions = newFindingVulnIds.stream()
                    .map(vulnId -> new FindingAttribution(vulnId, component.id(), component.projectId(),
                            convert(scanner).name(), UUID.randomUUID()))
                    .toList();
            dao.createFindingAttributions(findingAttributions);

            final var vulnIdByUuid = new HashMap<UUID, Long>();
            final var vulnUuidById = new HashMap<Long, UUID>();
            for (final Vulnerability vuln : vulns) {
                vulnIdByUuid.put(vuln.getUuid(), vuln.getId());
                vulnUuidById.put(vuln.getId(), vuln.getUuid());
            }

            // Unless we have any matching vulnerability policies, there's nothing more to do!
            if (policiesByVulnUuid.isEmpty()) {
                return vulnUuidById.entrySet().stream()
                        .filter(entry -> newFindingVulnIds.contains(entry.getKey()))
                        .map(Map.Entry::getValue)
                        .toList();
            }

            // For all vulnerabilities with matching policies, bulk-fetch existing analyses.
            // Index them by vulnerability UUID for more efficient access.
            final Map<UUID, Analysis> existingAnalyses = dao.getAnalyses(component, policiesByVulnUuid.keySet()).stream()
                    .collect(Collectors.toMap(Analysis::getVulnUuid, Function.identity()));

            final var analysesToCreateOrUpdate = new ArrayList<Analysis>();
            final var analysisCommentsByVulnId = new MultivaluedHashMap<Long, AnalysisComment>();
            for (final Map.Entry<UUID, VulnerabilityPolicy> vulnUuidAndPolicy : policiesByVulnUuid.entrySet()) {
                final UUID vulnUuid = vulnUuidAndPolicy.getKey();
                final VulnerabilityPolicy policy = vulnUuidAndPolicy.getValue();
                final String policyAnalysisCommenter = "[Policy] %s".formatted(policy.name());
                final Analysis policyAnalysis = Analysis.fromPolicyAnalysis(policy.analysis());
                final Analysis existingAnalysis = existingAnalyses.get(vulnUuid);
                if (existingAnalysis == null) {
                    policyAnalysis.setComponentId(component.id());
                    policyAnalysis.setProjectId(component.projectId());
                    policyAnalysis.setVulnId(vulnIdByUuid.get(vulnUuid));
                    policyAnalysis.setVulnUuid(vulnUuid);
                    if (policyAnalysis.getState() != null) {
                        analysisCommentsByVulnId.add(policyAnalysis.getVulnId(), new AnalysisComment(null, "State: NOT_SET → %s".formatted(policyAnalysis.getState()), policyAnalysisCommenter));
                    }
                    if (policyAnalysis.getJustification() != null) {
                        analysisCommentsByVulnId.add(policyAnalysis.getVulnId(), new AnalysisComment(null, "Justification: NOT_SET → %s".formatted(policyAnalysis.getJustification()), policyAnalysisCommenter));
                    }
                    if (policyAnalysis.getResponse() != null) {
                        analysisCommentsByVulnId.add(policyAnalysis.getVulnId(), new AnalysisComment(null, "Response: NOT_SET → %s".formatted(policyAnalysis.response), policyAnalysisCommenter));
                    }
                    if (policyAnalysis.getDetails() != null) {
                        analysisCommentsByVulnId.add(policyAnalysis.getVulnId(), new AnalysisComment(null, "Details: %s".formatted(policyAnalysis.details), policyAnalysisCommenter));
                    }
                    if (policyAnalysis.suppressed) {
                        analysisCommentsByVulnId.add(policyAnalysis.getVulnId(), new AnalysisComment(null, "Suppressed", policyAnalysisCommenter));
                    }
                    // TODO: Handle ratings
                    analysesToCreateOrUpdate.add(policyAnalysis);
                } else {
                    boolean shouldUpdate = false;
                    if (!Objects.equals(existingAnalysis.getState(), policyAnalysis.getState())) {
                        analysisCommentsByVulnId.add(existingAnalysis.getVulnId(), new AnalysisComment(existingAnalysis.getId(), "State: %s → %s".formatted(existingAnalysis.getState(), policyAnalysis.getState()), policyAnalysisCommenter));
                        existingAnalysis.setState(policyAnalysis.getState());
                        shouldUpdate = true;
                    }
                    if (!Objects.equals(existingAnalysis.getJustification(), policyAnalysis.getJustification())) {
                        analysisCommentsByVulnId.add(existingAnalysis.getVulnId(), new AnalysisComment(existingAnalysis.getId(), "Justification: %s → %s".formatted(existingAnalysis.justification, policyAnalysis.getJustification()), policyAnalysisCommenter));
                        existingAnalysis.setJustification(policyAnalysis.getJustification());
                        shouldUpdate = true;
                    }
                    if (!Objects.equals(existingAnalysis.getResponse(), policyAnalysis.getResponse())) {
                        analysisCommentsByVulnId.add(existingAnalysis.getVulnId(), new AnalysisComment(existingAnalysis.getId(), "Response: %s → %s".formatted(existingAnalysis.response, policyAnalysis.getResponse()), policyAnalysisCommenter));
                        existingAnalysis.setResponse(policyAnalysis.getResponse());
                        shouldUpdate = true;
                    }
                    if (policy.analysis().getDetails() != null && !Objects.equals(existingAnalysis.details, policy.analysis().getDetails())) {
                        analysisCommentsByVulnId.add(existingAnalysis.getVulnId(), new AnalysisComment(existingAnalysis.getId(), "Details: %s → %s".formatted(existingAnalysis.details, policyAnalysis.getDetails()), policyAnalysisCommenter));
                        existingAnalysis.setDetails(policy.analysis().getDetails());
                        shouldUpdate = true;
                    }
                    if (existingAnalysis.getSuppressed() == null || (existingAnalysis.getSuppressed() != policy.analysis().isSuppress())) {
                        analysisCommentsByVulnId.add(existingAnalysis.getVulnId(), new AnalysisComment(existingAnalysis.getId(), "Suppressed: %s → %s".formatted(existingAnalysis.suppressed, policyAnalysis.getSuppressed()), policyAnalysisCommenter));
                        existingAnalysis.setSuppressed(policy.analysis().isSuppress());
                        shouldUpdate = true;
                    }
                    // TODO: Handle ratings
                    if (shouldUpdate) {
                        analysesToCreateOrUpdate.add(existingAnalysis);
                    }
                }

                // If the policy outcome is a suppression, don't report the vulnerability.
                if (Boolean.TRUE.equals(policyAnalysis.getSuppressed())) {
                    newFindingVulnIds.remove(vulnIdByUuid.get(vulnUuid));
                }
            }

            if (!analysesToCreateOrUpdate.isEmpty()) {
                final List<CreatedAnalysis> createdAnalyses = dao.createOrUpdateAnalyses(analysesToCreateOrUpdate);

                // Comments for new analyses do not have an analysis ID set yet, as that ID is not known prior
                // to inserting the respective analysis record. Enrich comments with analysis IDs now that we know them.
                for (final CreatedAnalysis createdAnalysis : createdAnalyses) {
                    analysisCommentsByVulnId.computeIfPresent(createdAnalysis.vulnId, (vulnId, comments) -> comments.stream()
                            .map(comment -> new AnalysisComment(createdAnalysis.id, comment.comment(), comment.commenter()))
                            .toList());
                }

                dao.createAnalysisComments(analysisCommentsByVulnId.values().stream().flatMap(Collection::stream).toList());
            }

            return vulnUuidById.entrySet().stream()
                    .filter(entry -> newFindingVulnIds.contains(entry.getKey()))
                    .map(Map.Entry::getValue)
                    .toList();
        });
    }

    private void maybeSendNotifications(final QueryManager qm, final Component component, final boolean isNewComponent,
                                        final VulnerabilityAnalysisLevel analysisLevel, final List<UUID> newVulnUuids) {
        if (newVulnUuids.isEmpty()) {
            return;
        }

        final Timestamp notificationTimestamp = Timestamps.now();
        final var notifications = new ArrayList<org.dependencytrack.proto.notification.v1.Notification>();
        jdbi(qm).useExtension(NotificationSubjectDao.class, dao -> {
            if (isNewComponent) {
                dao.getForNewVulnerableDependency(component.uuid())
                        .map(subject -> org.dependencytrack.proto.notification.v1.Notification.newBuilder()
                                .setScope(SCOPE_PORTFOLIO)
                                .setGroup(GROUP_NEW_VULNERABLE_DEPENDENCY)
                                .setLevel(LEVEL_INFORMATIONAL)
                                .setTimestamp(notificationTimestamp)
                                .setSubject(Any.pack(subject))
                                .build())
                        .ifPresent(notifications::add);
            }

            dao.getForNewVulnerabilities(component.uuid(), newVulnUuids, analysisLevel).stream()
                    .map(subject -> org.dependencytrack.proto.notification.v1.Notification.newBuilder()
                            .setScope(SCOPE_PORTFOLIO)
                            .setGroup(GROUP_NEW_VULNERABILITY)
                            .setLevel(LEVEL_INFORMATIONAL)
                            .setTimestamp(notificationTimestamp)
                            .setSubject(Any.pack(subject))
                            .build())
                    .forEach(notifications::add);
        });

        for (final org.dependencytrack.proto.notification.v1.Notification notification : notifications) {
            eventDispatcher.dispatchAsync(component.projectUuid().toString(), notification);
        }
    }

    private boolean canUpdateVulnerability(final Vulnerability vuln, final Scanner scanner) {
        var canUpdate = true;

        // Results from the internal scanner only contain vulnId and source, nothing else.
        // As they only refer to existing vulnerabilities in the database, no update must be performed.
        canUpdate &= scanner != SCANNER_INTERNAL;

        // Internal vulnerabilities can only be updated via REST API.
        canUpdate &= !Vulnerability.Source.INTERNAL.name().equals(vuln.getSource());

        // If the scanner is also the authoritative source of the given vulnerability,
        // it should be able to update it. This will be the case for the OSS Index scanner
        // and sonatype-XXX vulnerabilities for example.
        canUpdate &= isAuthoritativeSource(vuln, convert(scanner))
                // Alternatively, if the vulnerability could be mirrored, but mirroring
                // is disabled, it is OK to override any existing data.
                //
                // Ideally, we'd track the data from all sources instead of just overriding
                // it, but for now this will have to do it.
                || (canBeMirrored(vuln) && !isMirroringEnabled(vuln));

        return canUpdate;
    }

    private static VulnerabilityAnalysisLevel determineAnalysisLevel(final FixedKeyRecord<?, ?> record) {
        return KafkaUtil.getEventHeader(record.headers(), KafkaEventHeaders.VULN_ANALYSIS_LEVEL)
                .map(value -> {
                    try {
                        return VulnerabilityAnalysisLevel.valueOf(value);
                    } catch (IllegalArgumentException e) {
                        LOGGER.warn("The reported analysis type %s is invalid, assuming %s"
                                .formatted(value, VulnerabilityAnalysisLevel.PERIODIC_ANALYSIS));
                        return VulnerabilityAnalysisLevel.PERIODIC_ANALYSIS;
                    }
                })
                .orElse(VulnerabilityAnalysisLevel.PERIODIC_ANALYSIS);
    }

    private static boolean determineIsComponentNew(final FixedKeyRecord<?, ?> record) {
        return KafkaUtil.getEventHeader(record.headers(), KafkaEventHeaders.IS_NEW_COMPONENT)
                .map(Boolean::parseBoolean)
                .orElse(false);
    }

    private static String prettyPrint(final ScanKey scanKey) {
        return "%s/%s".formatted(scanKey.getScanToken(), scanKey.getComponentUuid());
    }

    public interface Dao {

        @SqlQuery("""
                SELECT
                  "C"."ID"   AS "id",
                  "C"."UUID" AS "uuid",
                  "P"."ID"   AS "projectId",
                  "P"."UUID" AS "projectUuid"
                FROM
                  "COMPONENT" AS "C"
                INNER JOIN
                  "PROJECT" AS "P" ON "P"."ID" = "C"."PROJECT_ID"
                WHERE
                  "C"."UUID" = (:uuid)::TEXT
                """)
        @RegisterConstructorMapper(Component.class)
        Component getComponentByUuid(final UUID uuid);

        @SqlBatch("""
                INSERT INTO "COMPONENTS_VULNERABILITIES"
                  ("COMPONENT_ID", "VULNERABILITY_ID")
                VALUES
                  (:component.id, :vuln.id)
                ON CONFLICT DO NOTHING
                RETURNING "VULNERABILITY_ID"
                """)
        @GetGeneratedKeys("VULNERABILITY_ID")
        List<Long> createFindings(@BindMethods("component") final Component component, @BindBean("vuln") final Iterable<Vulnerability> vuln);

        @SqlBatch("""
                INSERT INTO "FINDINGATTRIBUTION"
                  ("VULNERABILITY_ID", "COMPONENT_ID", "PROJECT_ID", "ANALYZERIDENTITY", "ATTRIBUTED_ON", "UUID")
                VALUES
                  (:vulnId, :componentId, :projectId, :analyzer, NOW(), (:uuid)::TEXT)
                ON CONFLICT ("VULNERABILITY_ID", "COMPONENT_ID") DO NOTHING
                """)
        void createFindingAttributions(@BindMethods final Iterable<FindingAttribution> attribution);

        @SqlQuery("""
                SELECT
                  "V"."ID"            AS "vulnId",
                  "V"."UUID"          AS "vulnUuid",
                  "A"."ID"            AS "id",
                  "A"."COMPONENT_ID"  AS "componentId",
                  "A"."PROJECT_ID"    AS "projectId",
                  "A"."STATE"         AS "state",
                  "A"."JUSTIFICATION" AS "justification",
                  "A"."RESPONSE"      AS "response",
                  "A"."DETAILS"       AS "details",
                  "A"."SUPPRESSED"    AS "suppressed"
                FROM
                  "VULNERABILITY" AS "V"
                INNER JOIN
                  "ANALYSIS" AS "A" ON "A"."VULNERABILITY_ID" = "V"."ID"
                WHERE
                  "A"."COMPONENT_ID" = :component.id
                  AND "V"."UUID" = ANY((:vulnUuids)::TEXT[])
                """)
        @RegisterBeanMapper(Analysis.class)
        List<Analysis> getAnalyses(@BindMethods("component") final Component component, final Iterable<UUID> vulnUuids);

        @SqlBatch("""
                INSERT INTO "ANALYSIS"
                  ("VULNERABILITY_ID", "COMPONENT_ID", "PROJECT_ID", "STATE", "JUSTIFICATION", "RESPONSE", "DETAILS", "SUPPRESSED")
                VALUES
                  (:vulnId, :componentId, :projectId, :state, :justification, :response, :details, :suppressed)
                ON CONFLICT ("VULNERABILITY_ID", "COMPONENT_ID", "PROJECT_ID") DO UPDATE
                  SET
                    "STATE" = :state,
                    "JUSTIFICATION" = :justification,
                    "RESPONSE" = :response,
                    "DETAILS" = :details,
                    "SUPPRESSED" = :suppressed
                RETURNING "ID", "VULNERABILITY_ID"
                """)
        @GetGeneratedKeys({"ID", "VULNERABILITY_ID"})
        @RegisterConstructorMapper(CreatedAnalysis.class)
        List<CreatedAnalysis> createOrUpdateAnalyses(@BindBean final Iterable<Analysis> analysis);

        @SqlBatch("""
                INSERT INTO "ANALYSISCOMMENT"
                  ("ANALYSIS_ID", "TIMESTAMP", "COMMENT", "COMMENTER")
                VALUES
                  (:analysisId, NOW(), :comment, :commenter)
                """)
        void createAnalysisComments(@BindMethods final Iterable<AnalysisComment> comment);

    }

    public static class Analysis {

        private long id;
        private long componentId;
        private long projectId;
        private long vulnId;
        private UUID vulnUuid;
        private AnalysisState state;
        private AnalysisJustification justification;
        private AnalysisResponse response;
        private String details;
        private Boolean suppressed;

        private static Analysis fromPolicyAnalysis(final VulnerabilityPolicyAnalysis policyAnalysis) {
            final var analysis = new Analysis();
            if (policyAnalysis.getState() != null) {
                analysis.setState(switch (policyAnalysis.getState()) {
                    case EXPLOITABLE -> AnalysisState.EXPLOITABLE;
                    case FALSE_POSITIVE -> AnalysisState.FALSE_POSITIVE;
                    case IN_TRIAGE -> AnalysisState.IN_TRIAGE;
                    case NOT_AFFECTED -> AnalysisState.NOT_AFFECTED;
                    case RESOLVED -> AnalysisState.RESOLVED;
                });
            }
            if (policyAnalysis.getJustification() != null) {
                analysis.setJustification(switch (policyAnalysis.getJustification()) {
                    case CODE_NOT_PRESENT -> AnalysisJustification.CODE_NOT_PRESENT;
                    case CODE_NOT_REACHABLE -> AnalysisJustification.CODE_NOT_REACHABLE;
                    case PROTECTED_AT_PERIMETER -> AnalysisJustification.PROTECTED_AT_PERIMETER;
                    case PROTECTED_AT_RUNTIME -> AnalysisJustification.PROTECTED_AT_RUNTIME;
                    case PROTECTED_BY_COMPILER -> AnalysisJustification.PROTECTED_BY_COMPILER;
                    case PROTECTED_BY_MITIGATING_CONTROL -> AnalysisJustification.PROTECTED_BY_MITIGATING_CONTROL;
                    case REQUIRES_CONFIGURATION -> AnalysisJustification.REQUIRES_CONFIGURATION;
                    case REQUIRES_DEPENDENCY -> AnalysisJustification.REQUIRES_DEPENDENCY;
                    case REQUIRES_ENVIRONMENT -> AnalysisJustification.REQUIRES_ENVIRONMENT;
                });
            }
            if (policyAnalysis.getResponse() != null) {
                analysis.setResponse(switch (policyAnalysis.getResponse()) {
                    case CAN_NOT_FIX -> AnalysisResponse.CAN_NOT_FIX;
                    case ROLLBACK -> AnalysisResponse.ROLLBACK;
                    case UPDATE -> AnalysisResponse.UPDATE;
                    case WILL_NOT_FIX -> AnalysisResponse.WILL_NOT_FIX;
                    case WORKAROUND_AVAILABLE -> AnalysisResponse.WORKAROUND_AVAILABLE;
                });
            }
            if (policyAnalysis.getDetails() != null) {
                analysis.setDetails(policyAnalysis.getDetails());
            }
            analysis.setSuppressed(policyAnalysis.isSuppress());
            return analysis;
        }

        public long getId() {
            return id;
        }

        public void setId(final long id) {
            this.id = id;
        }

        public long getComponentId() {
            return componentId;
        }

        public void setComponentId(final long componentId) {
            this.componentId = componentId;
        }

        public long getProjectId() {
            return projectId;
        }

        public void setProjectId(final long projectId) {
            this.projectId = projectId;
        }

        public long getVulnId() {
            return vulnId;
        }

        public void setVulnId(final long vulnId) {
            this.vulnId = vulnId;
        }

        public UUID getVulnUuid() {
            return vulnUuid;
        }

        public void setVulnUuid(final UUID vulnUuid) {
            this.vulnUuid = vulnUuid;
        }

        public AnalysisState getState() {
            return state;
        }

        public void setState(final AnalysisState state) {
            this.state = state;
        }

        public AnalysisJustification getJustification() {
            return justification;
        }

        public void setJustification(final AnalysisJustification justification) {
            this.justification = justification;
        }

        public AnalysisResponse getResponse() {
            return response;
        }

        public void setResponse(final AnalysisResponse response) {
            this.response = response;
        }

        public String getDetails() {
            return details;
        }

        public void setDetails(final String details) {
            this.details = details;
        }

        public Boolean getSuppressed() {
            return suppressed;
        }

        public void setSuppressed(final Boolean suppressed) {
            this.suppressed = suppressed;
        }

    }

    public record CreatedAnalysis(long id, @ColumnName("VULNERABILITY_ID") long vulnId) {
    }

    public record AnalysisComment(Long analysisId, String comment, String commenter) {
    }

    public record Component(long id, UUID uuid, long projectId, UUID projectUuid) {
    }

    public record FindingAttribution(long vulnId, long componentId, long projectId, String analyzer, UUID uuid) {
    }

}
